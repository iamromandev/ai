# A minimal note on AI created with LOVE.

### Gradient
> **"A gradient measures how much the output of a function changes if you change the inputs a little bit." — Lex Fridman (MIT)**

A gradient simply measures the change in all weights with regard to the change in error. You can also think of a gradient as the slope of a function. The higher the gradient, the steeper the slope and the faster a model can learn. But if the slope is zero, the model stops learning. In mathematical terms, a gradient is a partial derivative with respect to its inputs.

### Gradient Descent


#### Types of Gradient Descent:
1. Batch Gradient Descent
2. Stochastic Gradient Descent
3. Mini-batch Gradient Descent



